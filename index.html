<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content='width=800'>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from nupur kumari */
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 12px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22 px;
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 13px;
      font-weight: 700
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    img {
      display: inline;
      margin: 0 auto;
      width: 100%;
    }

    .image-cropper {
      width: 250px;
      height: 250px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
    }

    .center {
      text-align: center;
    }
  </style>
  <link rel="icon" type="image" href="img/logo.jpg">
  <title>Purushothaman Natarajan</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Purushothaman Natarajan</name>
              </p>
              <p align>I am an R&D Data Scientist based in Chennai, India. I am currently working towards my PhD in large-scale vector search. In addition, I work in 
                an organization focused on developing vision, NLP, and generative AI models that drive revenue and minimize human effort for our clients. My research 
                interests lie in Computer Vision and Natural Language Processing (NLP), specifically visual language models and explainable AI (XAI), with additional 
                interests in self-supervised learning and few-shot learning. 
              </p>
              <br>
              <p align="center">
                <a href="mailto:purushothamann@icloud.com">Email</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/purushothamann">LinkedIn</a> &nbsp;/&nbsp;
                <a href="files/Resume.pdf">Resume</a> &nbsp;/&nbsp;
                <a href="https://github.com/Purushothaman-natarajan">GitHub</a>
              </p>
            </td>
            <td width="50%"><img class="image-cropper" src="img/photo.jpg"></td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <br>
            <heading style="font-size:20px"> Submitted Publications</heading>
          </tr>

          <tr>
            <td valign="top" width="100%" class="left">  
                <papertitle>Synth-SONAR: Sonar Image Synthesis with Enhanced Diversity and Realism via Dual Diffusion Models and GPT Prompting</papertitle>
                  <br>
                  <i><span style="font-size: 10pt;"></span> Purushothaman Natarajan, Kamal Basha, Athira Nambiar </i>
                  
                  </p>
                      <!-- WACV - 2024 &nbsp;&nbsp;<span style="font-size: 10pt;"> -->
                      [<a href="https://arxiv.org/pdf/2410.08612">Paper</a>]
                      [<a href="https://github.com/Purushothaman-natarajan/Synth-SONAR">Code</a>]
                      </a> 
                      </span>
                  </p>
          
                  <p align>Sonar image synthesis is crucial for advancing applications in underwater exploration, marine biology, and defence. Traditional methods often rely 
                    on extensive and expensive data collection using sonar sensors, jeopardizing data quality and diversity. To overcome these limitations, this study proposes 
                    a new sonar image synthesis framework, Synth-SONAR leveraging diffusion models and GPT prompting. The key novelties of Synth-SONAR are 
                    threefold: First, by integrating Generative AI-based style injection techniques along with publicly available real/simulated data, thereby producing 
                    one of the largest sonar data corpus for sonar research. Second, a dual text-conditioning sonar diffusion model hierarchy synthesizes coarse and 
                    fine-grained sonar images with enhanced quality and diversity. Third, high-level (coarse) and low-level (detailed) text-based sonar generation 
                    methods leverage advanced semantic information available in visual language models (VLMs) and GPT-prompting. During inference, the method generates 
                    diverse and realistic sonar images from textual prompts, bridging the gap between textual descriptions and sonar image generation. This marks 
                    the application of GPT-prompting in sonar imagery for the first time, to the best of our knowledge. Synth-SONAR achieves state-of-the-art results 
                    in producing high-quality synthetic sonar datasets, significantly enhancing their diversity and realism.
                  </p>
                  <br>
          
                  <papertitle>VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models</papertitle>
                  <br>
                  <i><span style="font-size: 10pt;"></span> Purushothaman Natarajan, Athira Nambiar </i>
                  
                  </p>
                      <!-- CVIP - 2024 &nbsp;&nbsp;<span style="font-size: 10pt;">  -->
                      [<a href="https://www.arxiv.org/abs/2408.12808">Paper</a>]
                      [<a href="https://github.com/Purushothaman-natarajan/VALE-Explainer">Code</a>]
                      </a> 
                      </span>
                  </p>
          
                  <p align>A novel multimodal Explainable AI (XAI) framework known as VALE. VALE integrates image classification 
                    with SHAP for visual explanations and utilizes the Segment Anything Model (SAM) for precise object segmentation. It enhances interpretability 
                    by employing Vision Language Models (VLMs) to generate clear textual explanations from visual inputs, addressing the semantic gap between modalities. 
                    Demonstrated on tasks like ImageNet classification and specialized applications such as underwater SONAR image analysis, LAVE underscores its adaptability
                    and performance through prompt engineering and transfer learning for real-world applications such as defense.
                  </p>
                  <br>
          
                <papertitle>Underwater SONAR Image Classification and Analysis using LIME-based Explainable AI</papertitle>
                  <br>
                  <i><span style="font-size: 10pt;"></span> Purushothaman Natarajan, Athira Nambiar </i>
                  
                  </p>
                      <!-- IEEE Journal of Oceanic Engineering - 2023 &nbsp;&nbsp;<span style="font-size: 10pt;"> -->
                      [<a href="https://arxiv.org/abs/2408.12837">Paper</a>]
                      [<a href="https://github.com/Purushothaman-natarajan/Under-water-sonar-image-classification">Code</a>]
                      </a> 
                      </span>
                  </p>
            
                  <p align>This research explores the application of Explainable Artificial Intelligence (XAI) to enhance interpretability in underwater image 
                    classification, marking a pioneering effort in the field. Utilizing custom datasets including Seabed Objects KLSG, camera SONAR, mine SONAR 
                    images, and SCTD, extensive analysis of transfer learning techniques is conducted across prominent Convolutional Neural Network (CNN) 
                    architectures. The research integrates Local Interpretable Model-Agnostic Explanations (LIME) and Submodular Picks LIME (SP-LIME), 
                    leveraging algorithms like Quickshift and Simple Linear Iterative Clustering (SLIC) for image perturbation. These XAI techniques provide 
                    transparent justifications for model decisions, essential for deploying AI systems in high-security domains with confidence and reliability.
                  </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <heading style="font-size:20px"> Education</heading>
          </tr>

          <tr>
            <td valign="top" width="100%" class="left">
                <li><strong>PhD in Computer Science, SRM University (Feb 2024 - Aug 2024) - Drop-out</strong>
                  <ul>
                    <p>Coursework: Computer Architecture, Artificial Intelligence, Comparison of Learning Algorithms, Computational Theory</p>
                  </ul>
                </li>
                <li><strong>M.Tech in Data Science, BITS Pilani (Sept 2022 - Sept 2024)</strong>
                  <ul>
                    <p>CGPA: 8.38/10</p>
                    <p>Coursework: Data Science, Applied Machine Learning, Deep Learning, Natural Language Processing, Information Retrieval, Artificial 
                      and Computational Intelligence</p>
                  </ul>
                </li>
                <li><strong>B.E in Mechanical Engineering, Anna University (Aug 2015 - Nov 2020)</strong>
                  <ul>
                    <p>CGPA: 6.50/10<p>
                    <p>Coursework: Design Thinking, Engineering Mechanics, Thermodynamics, Fluid Mechanics, Manufacturing Engineering</p>
                  </ul>
                </li>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <heading style="font-size:20px"> Experience</heading>
          </tr>

            <td valign="top" width="100%" class="left">
                <li><strong>Data Scientist, Blackstraw, Chennai, IN (Nov 2024 - Present)</strong>
                  <ul>
                    <li>R&D in computer vision, NLP, and generative AI to develop advanced AI-driven solutions for various products.</li>
                    <li>Enhancing automation and optimizing revenue through AIML models.</li>
                    <li>Building scalable artificial intelligence frameworks for practical applications across various industries.</li>
                  </ul>
                </li>
                <li><strong>Research Fellow (Machine Learning & eXplainable AI), SRMIST, Chennai, IN (Sept 2023 - Oct 2024)</strong>
                  <ul>
                    <li>Developing algorithms for underwater sonar image detection, enhancing surveillance capabilities.</li>
                    <li>Integrated Explainable AI for transparency and trust in defense applications.</li>
                    <li>Delivered self-explainable AI models tested by NPOL, DRDO, and the Defense Ministry of India.</li>
                  </ul>
                </li>
                <li><strong>Machine Learning Associate, Amazon, Chennai, IN (Aug 2022 - May 2023)</strong>
                  <ul>
                    <li>Handled data quality for Alexa, Ring, and Halo products.</li>
                    <li>Utilized NLTK and SpaCy for text preprocessing and Pandas and NumPy for data cleaning and preprocessing.</li>
                    <li>Designed performance dashboards for data-driven decision-making.</li>
                  </ul>
                </li>
                <li><strong>Customer Support Executive, Amazon, Coimbatore, IN (Aug 2021 - Nov 2021)</strong>
                  <ul>
                    <li>Developed data cleaning and preprocessing pipelines using Python libraries.</li>
                    <li>Designed real-time prediction dashboards with Tableau, monitoring system health and performance metrics.</li>
                  </ul>
                </li>
            </td>
        </table>

        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <heading style="font-size:20px"> Skills</heading>
          </tr>

          <tr>
            <td valign="top" width="100%" class="left">
                <li><strong>Languages:</strong> Python, JavaScript, TypeScript, SQL</li>
                <li><strong>Technologies & Tools:</strong> PyTorch, TensorFlow, OpenCV, Git, NLTK, Matplotlib, Tableau, Spark, Kubernetes, Docker</li>
                <li><strong>Cloud Platforms:</strong> GCP, AWS</li>
              </ul>
            </td>
          </tr>
        </table>

        
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <br>
          <tr>
            <heading style="font-size:20px"> Projects</heading>
          </tr>

          <tr>
            <td valign="top" width="100%" class="left">
                <li><strong>Q&A Chatbot from PDF</strong> [<a href="https://github.com/Purushothaman-natarajan/Q-and-A-chat-bot-from-PDF">GitHub Link</a>]
                  <ul>
                    <li>Chatbot for answering queries from PDFs using BERT.</li>
                    <li>Tools: Python, Transformers, NLTK, Gradio, TensorFlow.</li>
                  </ul>
                </li>
                <li><strong>XAI for AID Scene Classification on Remote Sensing</strong> [<a href="https://github.com/Purushothaman-natarajan/eXplainable-AI-for-Image-Classification-on-Remote-Sensing">GitHub Link</a>]
                  <ul>
                    <li>Scene classification with transfer learning and prediction explanations using LIME and Grad-CAM.</li>
                    <li>Tools: Python, TensorFlow, Scikit-learn, LIME, Grad-CAM, Gradio.</li>
                  </ul>
                </li>
                <li><strong>Piezoelectric Generator</strong>
                  <ul>
                    <li>Transducer to collect energy from mechanical vibrations to power microdevices.</li>
                    <li>Tools: SolidWorks, CAD.</li>
                  </ul>
                </li>
            </td>
          </tr>
        </table>

        
        <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <br>
          <tr>
            <heading style="font-size:20px"> Additional Experience and Awards</heading>
          </tr>
          <tr>
            <td valign="top" width="100%" class="left">
                <li><strong>Instructor, BrightNext Academy (2024-Present)</strong>
                  <ul>
                    <li>Taught Machine Learning and Deep Learning courses.</li>
                  </ul>
                </li>
                <li><strong>Freelancer (Upwork and LinkedIn) (2022-2024)</strong>
                  <ul>
                    <li>Delivered AI and ML projects valued between $10K to $20K.</li>
                  </ul>
                </li>
                <li><strong>Third Prize, Innovation & Design on Remote Sensing Data</strong>
                  <ul>
                    <li>Recognized for designing a dashboard for an explainable image classifier.</li>
                  </ul>
                </li>
            </td>
          </tr>
        </table>

      
      </td>
    </tr>
  </table>
</body>


<!-- Default Statcounter code for Portfolio
https://purushothaman-natarajan.github.io/ -->
<script type="text/javascript">
    var sc_project=13018506; 
    var sc_invisible=1; 
    var sc_security="5dd7fec5"; 
    </script>
    <script type="text/javascript"
    src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript><div class="statcounter"><a title="free web stats"
    href="https://statcounter.com/" target="_blank"><img class="statcounter"
    src="https://c.statcounter.com/13018506/0/5dd7fec5/1/" alt="free web stats"
    referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
    <!-- End of Statcounter Code -->


</html>
